{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLOv3_Training.ipynb","provenance":[{"file_id":"1_GdoqCJWXsChrOiY8sZMr_zbr_fH-0Fg","timestamp":1615606339040}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iZULaGX7_H1u"},"source":["# A YOLOv3 Object Detector with Darknet in the Cloud (GPU ENABLED)\n","This notebook copies over training and validation data, configuration files, and code needed to train a YOLOv3 network.   It is set up to classify and locate a single class (\"Box\")."]},{"cell_type":"markdown","metadata":{"id":"gE3azXoR_pWi"},"source":["# Step 1: Cloning the repository\n","The following cells will clone a repository from Erik Lindernoren."]},{"cell_type":"code","metadata":{"id":"68eMertgIxaB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616210366022,"user_tz":420,"elapsed":5942,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"55a795eb-80ec-4d7e-90f1-303580276948"},"source":["# clone darknet repo\n","#!git clone https://github.com/AlexeyAB/darknet\n","!git clone https://github.com/eriklindernoren/PyTorch-YOLOv3"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'PyTorch-YOLOv3'...\n","remote: Enumerating objects: 67, done.\u001b[K\n","remote: Counting objects: 100% (67/67), done.\u001b[K\n","remote: Compressing objects: 100% (39/39), done.\u001b[K\n","remote: Total 1032 (delta 36), reused 49 (delta 28), pack-reused 965\u001b[K\n","Receiving objects: 100% (1032/1032), 16.25 MiB | 4.49 MiB/s, done.\n","Resolving deltas: 100% (596/596), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x29jd6sVbhOo"},"source":["# The next cell just makes sure that all the requirements for the code are installed."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NuPhMrE3EmkS","executionInfo":{"status":"ok","timestamp":1616210375709,"user_tz":420,"elapsed":8562,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"5d8fc098-ac4d-47db-aa36-9b74650dc814"},"source":["%cd /content/PyTorch-YOLOv3\n","!pwd\n","!sudo pip3 install -r requirements.txt\n","#!sudo pip install imgaug\n","\n","import torch\n","#import imgaug\n","#from imgaug import *\n","#from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/PyTorch-YOLOv3\n","/content/PyTorch-YOLOv3\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.8.0+cu101)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.9.0+cu101)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n","Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.4.1)\n","Collecting terminaltables\n","  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.41.1)\n","Collecting imgaug>=0.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n","\u001b[K     |████████████████████████████████| 952kB 13.7MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->-r requirements.txt (line 2)) (3.7.4.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (1.27.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (0.4.3)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (3.12.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (54.1.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (1.15.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (3.3.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (2.23.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (1.32.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (0.10.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->-r requirements.txt (line 5)) (0.36.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4->-r requirements.txt (line 9)) (4.1.2.30)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4->-r requirements.txt (line 9)) (1.7.1)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4->-r requirements.txt (line 9)) (2.4.1)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4->-r requirements.txt (line 9)) (0.16.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4->-r requirements.txt (line 9)) (1.4.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->-r requirements.txt (line 5)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->-r requirements.txt (line 5)) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->-r requirements.txt (line 5)) (4.2.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->-r requirements.txt (line 5)) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.15->-r requirements.txt (line 5)) (3.7.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->-r requirements.txt (line 5)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->-r requirements.txt (line 5)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->-r requirements.txt (line 5)) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->-r requirements.txt (line 5)) (2.10)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4->-r requirements.txt (line 9)) (2.5)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4->-r requirements.txt (line 9)) (1.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.15->-r requirements.txt (line 5)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->-r requirements.txt (line 5)) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.15->-r requirements.txt (line 5)) (3.4.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4->-r requirements.txt (line 9)) (4.4.2)\n","Building wheels for collected packages: terminaltables\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=49e774ef5e60f74e49a8a4876a7b5088d17c9df53c8223a779e50d99c3723100\n","  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n","Successfully built terminaltables\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.4.0 which is incompatible.\u001b[0m\n","Installing collected packages: terminaltables, imgaug\n","  Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed imgaug-0.4.0 terminaltables-3.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LCNUsfgJb5wD"},"source":["# Step 2:  Download weights from Coco training if desired"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7WvOxrU8zlrZ","executionInfo":{"status":"ok","timestamp":1616210428631,"user_tz":420,"elapsed":50004,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"dcf690bb-42ba-4298-d216-56193c4d533d"},"source":["# If needed, you can Download some pre-trained weights from Coco.  Not necessary in this case\n","#\n","%cd ..\n","%cd PyTorch-YOLOv3\n","%cd weights\n","\n","!bash download_weights.sh\n","%cd .."],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content\n","/content/PyTorch-YOLOv3\n","/content/PyTorch-YOLOv3/weights\n","--2021-03-20 03:19:38--  https://pjreddie.com/media/files/yolov3.weights\n","Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 248007048 (237M) [application/octet-stream]\n","Saving to: ‘yolov3.weights’\n","\n","yolov3.weights      100%[===================>] 236.52M  3.64MB/s    in 29s     \n","\n","2021-03-20 03:20:07 (8.29 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n","\n","--2021-03-20 03:20:07--  https://pjreddie.com/media/files/yolov3-tiny.weights\n","Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 35434956 (34M) [application/octet-stream]\n","Saving to: ‘yolov3-tiny.weights’\n","\n","yolov3-tiny.weights 100%[===================>]  33.79M  8.50MB/s    in 5.3s    \n","\n","2021-03-20 03:20:13 (6.36 MB/s) - ‘yolov3-tiny.weights’ saved [35434956/35434956]\n","\n","--2021-03-20 03:20:13--  https://pjreddie.com/media/files/darknet53.conv.74\n","Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 162482580 (155M) [application/octet-stream]\n","Saving to: ‘darknet53.conv.74’\n","\n","darknet53.conv.74   100%[===================>] 154.96M  7.92MB/s    in 13s     \n","\n","2021-03-20 03:20:28 (11.5 MB/s) - ‘darknet53.conv.74’ saved [162482580/162482580]\n","\n","/content/PyTorch-YOLOv3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5uloUwmUKF05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616210431410,"user_tz":420,"elapsed":524,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"c7f35677-89cd-4e3e-c7bb-81cbfec5f986"},"source":["# verify CUDA\n","!/usr/local/cuda/bin/nvcc --version"],"execution_count":4,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Wed_Jul_22_19:09:09_PDT_2020\n","Cuda compilation tools, release 11.0, V11.0.221\n","Build cuda_11.0_bu.TC445_37.28845127_0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4z0wLgzFcF3S"},"source":["# Step 3:  Mount your Google Drive, and upload data into the Cloud"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xp52Hiio7pt2","executionInfo":{"status":"ok","timestamp":1616210460202,"user_tz":420,"elapsed":25854,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"fa666a0c-6f2a-4c5c-c883-5a39b9c77acf"},"source":["!ls\n","%cd ..\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["assets\tdata\t   LICENSE    README.md\t\ttest.py   utils\n","config\tdetect.py  models.py  requirements.txt\ttrain.py  weights\n","/content\n","Mounted at /content/gdrive\n","gdrive\tPyTorch-YOLOv3\tsample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSGhFb-E8GoQ","executionInfo":{"status":"ok","timestamp":1616210462459,"user_tz":420,"elapsed":542,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"56d8a66d-a0f8-49c2-abff-cb3217cadeea"},"source":["!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","!ls /mydrive"],"execution_count":6,"outputs":[{"output_type":"stream","text":["'Colab Notebooks'   CS231A_project  'My Drive'\t obj.data   yolov3   yolov4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmxB_w9g8OjO","executionInfo":{"status":"ok","timestamp":1616210579535,"user_tz":420,"elapsed":3521,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"8a3e9ca2-cff8-47ed-f42f-8a9c6e7f763e"},"source":["%cd /content/PyTorch-YOLOv3/data/custom/\n","!rm images/train.jpg  # Left over from github install (not wanted)\n","#!ls images\n","#!cp /mydrive/CS231A_project/Data/train_3D_yolov3/custom_images.zip .\n","#!cp /mydrive/CS231A_project/Data/train_3D_yolov3/custom_labels.zip .\n","!cp /mydrive/CS231A_project/Data/train_3D_yolov3/custom_images_hot.zip .\n","!cp /mydrive/CS231A_project/Data/train_3D_yolov3/custom_labels_hot.zip .\n","!unzip -nq custom_images_hot.zip\n","!unzip -nq custom_labels_hot.zip\n","\n","%mkdir /content/PyTorch-YOLOv3/data/custom/validation\n","%cd /content/PyTorch-YOLOv3/data/custom/validation/\n","!cp /mydrive/CS231A_project/Data/test_3D_yolov3/custom_images.zip .\n","!cp /mydrive/CS231A_project/Data/test_3D_yolov3/custom_labels.zip .\n","!unzip -nq custom_images.zip\n","!unzip -nq custom_labels.zip\n","\n","%cd /content/PyTorch-YOLOv3/\n","!cp /mydrive/yolov3/generate*.py .\n","# Above copies the generate_train.py and generate_test.py to the cloud\n","\n","!python generate_train.py\n","!python generate_test.py\n","# Generate the train.txt and valid.txt files in data/custom\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/PyTorch-YOLOv3/data/custom\n","rm: cannot remove 'images/train.jpg': No such file or directory\n","mkdir: cannot create directory ‘/content/PyTorch-YOLOv3/data/custom/validation’: File exists\n","/content/PyTorch-YOLOv3/data/custom/validation\n","/content/PyTorch-YOLOv3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gGzkTV4pcQZ9"},"source":["# Make sure that the label annotations do not have any comma's."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAZRJFbeNkpC","executionInfo":{"status":"ok","timestamp":1616210605048,"user_tz":420,"elapsed":2099,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"302230ec-fbf3-4692-86eb-dc6dba789bee"},"source":["%cd /content/PyTorch-YOLOv3/\n","!pwd\n","\n","!cp /mydrive/yolov3/comm_out_labels.py .\n","!cp /mydrive/yolov3/comm_out_valid_labels.py .\n","#!ls data/custom/labels/train_image_00067.txt*\n","!python comm_out_labels.py\n","!python comm_out_valid_labels.py"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/PyTorch-YOLOv3\n","/content/PyTorch-YOLOv3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TGbem5i5rXJ","executionInfo":{"status":"ok","timestamp":1616098055009,"user_tz":420,"elapsed":1844,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"8d7a8b02-9d70-4580-f046-d38b504bb4de"},"source":["%cd /content/PyTorch-YOLOv3/config/\n","#!bash create_custom_model.sh <num-classes> # Will create custom model 'yolov3-custom.cfg'\n","!bash create_custom_model.sh 1 # Will create custom model 'yolov3-custom.cfg' for a single class\n","\n","# But, this will be overwritten by a saved copy in next block\n","%cd ../\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/PyTorch-YOLOv3/config\n","/content/PyTorch-YOLOv3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Wu0RuCq5-Uo","executionInfo":{"status":"ok","timestamp":1616210617606,"user_tz":420,"elapsed":2026,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"41c6f91a-bdb0-42a9-f7cc-f48c8ffd2269"},"source":["# This assumes that a custom yolov3-custom.cfg file has been generated \n","#     and edited and left in /mydrive/yolov3\n","%cd /content/PyTorch-YOLOv3/\n","!cp /mydrive/yolov3/classes.names data/custom/.\n","\n","%cd /content/PyTorch-YOLOv3/config\n","!cp /mydrive/yolov3/yolov3-custom.cfg .\n","#!ls -al data/custom/classes.names\n","#!more data/custom/classes.names\n","!ls -al\n","#!cp yolov3-custom.cfg /mydrive/yolov3/.\n","%cd /content/PyTorch-YOLOv3/"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/content/PyTorch-YOLOv3\n","/content/PyTorch-YOLOv3/config\n","total 56\n","drwxr-xr-x 2 root root 4096 Mar 20 03:23 .\n","drwxr-xr-x 8 root root 4096 Mar 20 03:23 ..\n","-rw-r--r-- 1 root root  115 Mar 20 03:19 coco.data\n","-rw-r--r-- 1 root root 8532 Mar 20 03:19 create_custom_model.sh\n","-rw-r--r-- 1 root root   99 Mar 20 03:19 custom.data\n","-rw-r--r-- 1 root root 8338 Mar 20 03:19 yolov3.cfg\n","-rw------- 1 root root 8368 Mar 20 03:23 yolov3-custom.cfg\n","-rw-r--r-- 1 root root 2025 Mar 20 03:19 yolov3-tiny.cfg\n","/content/PyTorch-YOLOv3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YNEHfNTvcZ0C"},"source":["# Step 4:  Get ready for training.  First upload modified code."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hutQqE_xzpGy","executionInfo":{"status":"ok","timestamp":1616210627143,"user_tz":420,"elapsed":1828,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"6b7ff82f-af4d-41d6-eff8-0cde59eda75f"},"source":["!cp /mydrive/yolov3/train.py train.py\n","!cp /mydrive/yolov3/detect.py detect.py\n","!ls -al train.py"],"execution_count":11,"outputs":[{"output_type":"stream","text":["-rw-r--r-- 1 root root 7585 Mar 20 03:23 train.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwToiJwTIplB","executionInfo":{"status":"ok","timestamp":1616162846329,"user_tz":420,"elapsed":31432,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"c7f0f14e-03d1-42f0-bd76-c2b298e22d02"},"source":["!tensorboard --logdir='logs' --port=6006"],"execution_count":20,"outputs":[{"output_type":"stream","text":["2021-03-19 14:06:56.064520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n","TensorBoard 2.4.1 at http://localhost:6006/ (Press CTRL+C to quit)\n","^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0v4FYqvmcjcW"},"source":["# Step 5:  Then Training can begin!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGbx3ko73ocW","executionInfo":{"status":"ok","timestamp":1616213738020,"user_tz":420,"elapsed":1700601,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"6b3c9660-2bc4-446e-b774-76babe284949"},"source":["#  To start training on YOLOv3\n","#\n","%cd /content/PyTorch-YOLOv3\n","\n","!python3 train.py --model_def config/yolov3-custom.cfg --data_config config/custom.data\n","\n","!cp weights/wgts_50_74 /mydrive/yolov3/wgts_50_hot_74\n","!cp weights/wgts_50_all /mydrive/yolov3/wgts_50_hot_all"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content/PyTorch-YOLOv3\n","Namespace(batch_size=8, checkpoint_interval=1, compute_map=False, data_config='config/custom.data', epochs=50, evaluation_interval=1, gradient_accumulations=2, img_size=416, logdir='logs', model_def='config/yolov3-custom.cfg', multiscale_training=True, n_cpu=8, pretrained_weights=None, verbose=False)\n","2021-03-20 03:47:19.342881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Training Epoch 0: 100% 101/101 [01:55<00:00,  1.14s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.69it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 666.71it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.39340 |\n","+-------+------------+---------+\n","---- mAP 0.39340305288891186\n","Training Epoch 1: 100% 101/101 [01:55<00:00,  1.14s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.69it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 627.23it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.13011 |\n","+-------+------------+---------+\n","---- mAP 0.1301117578651467\n","Training Epoch 2: 100% 101/101 [01:54<00:00,  1.13s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.62it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1109.90it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.27027 |\n","+-------+------------+---------+\n","---- mAP 0.27026869745100685\n","Training Epoch 3: 100% 101/101 [01:54<00:00,  1.14s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.61it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1180.50it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.52187 |\n","+-------+------------+---------+\n","---- mAP 0.5218679382543672\n","Training Epoch 4: 100% 101/101 [01:55<00:00,  1.15s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.65it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1573.26it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.60779 |\n","+-------+------------+---------+\n","---- mAP 0.6077934373542571\n","Training Epoch 5: 100% 101/101 [01:55<00:00,  1.14s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:05<00:00,  2.56it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1493.17it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.94148 |\n","+-------+------------+---------+\n","---- mAP 0.9414834668044431\n","Training Epoch 6: 100% 101/101 [01:55<00:00,  1.15s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.64it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1639.68it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.37520 |\n","+-------+------------+---------+\n","---- mAP 0.37520491273432444\n","Training Epoch 7: 100% 101/101 [01:55<00:00,  1.15s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.65it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1278.75it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.46443 |\n","+-------+------------+---------+\n","---- mAP 0.4644253417740281\n","Training Epoch 8: 100% 101/101 [01:55<00:00,  1.14s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.71it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1596.01it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.59717 |\n","+-------+------------+---------+\n","---- mAP 0.5971697704939434\n","Training Epoch 9: 100% 101/101 [01:55<00:00,  1.14s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.72it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1431.50it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.86964 |\n","+-------+------------+---------+\n","---- mAP 0.8696381746066923\n","Training Epoch 10: 100% 101/101 [01:56<00:00,  1.15s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.66it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1565.62it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.29193 |\n","+-------+------------+---------+\n","---- mAP 0.29192687806996975\n","Training Epoch 11: 100% 101/101 [01:55<00:00,  1.15s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.62it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1817.29it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.98078 |\n","+-------+------------+---------+\n","---- mAP 0.9807750906929125\n","Training Epoch 12: 100% 101/101 [01:55<00:00,  1.15s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.66it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1159.29it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.34700 |\n","+-------+------------+---------+\n","---- mAP 0.3470039717376293\n","Training Epoch 13: 100% 101/101 [01:54<00:00,  1.14s/it]\n","\n","---- Evaluating Model ----\n","Detecting objects: 100% 13/13 [00:04<00:00,  2.66it/s]\n","Computing AP: 100% 1/1 [00:00<00:00, 1576.81it/s]\n","+-------+------------+---------+\n","| Index | Class name | AP      |\n","+-------+------------+---------+\n","| 0     | Box        | 0.92352 |\n","+-------+------------+---------+\n","---- mAP 0.9235236715367303\n","Training Epoch 14:   0% 0/101 [00:00<?, ?it/s]src/tcmalloc.cc:283] Attempt to free invalid pointer 0x1 \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n","    self.not_empty.wait(remaining)\n","  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n","    gotit = waiter.acquire(True, timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n","    _error_if_any_worker_fails()\n","RuntimeError: DataLoader worker (pid 2256) is killed by signal: Aborted. \n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"train.py\", line 105, in <module>\n","    for batch_i, (_, imgs, targets) in enumerate(tqdm.tqdm(dataloader, desc=f\"Training Epoch {epoch}\")):\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1104, in __iter__\n","    for obj in iterable:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n","    idx, data = self._get_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1138, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 999, in _try_get_data\n","    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e\n","RuntimeError: DataLoader worker (pid(s) 2256) exited unexpectedly\n","Training Epoch 14:   0% 0/101 [00:00<?, ?it/s]\n","cp: cannot stat 'weights/wgts_50_74': No such file or directory\n","cp: cannot stat 'weights/wgts_50_all': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RdWfAFLhcs3e"},"source":["# The previous block will save weights to the Google Drive so that all is not lost when Google disconnects this session from the Cloud."]},{"cell_type":"markdown","metadata":{"id":"07Lfm0IdZtMd"},"source":["#\n","#\n","# *The next section is for running detection on sample images.   It uses the last checkpoint (weights) of the training.*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TytgZSulxRkq","executionInfo":{"status":"ok","timestamp":1616205404851,"user_tz":420,"elapsed":8449,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"56cb088c-2b7e-404c-f895-13c822a6ed97"},"source":["!python3 detect.py --model_def config/yolov3-custom.cfg --class_path data/custom/classes.names  --conf_thres=0.4 --checkpoint_model /mydrive/yolov3/checkpoints/yolov3_ckpt_49.pth --image_folder /mydrive/yolov3/test/samples --weights_path /mydrive/yolov3/checkpoints/yolov3_ckpt_49.pth\n","#!python3 detect.py --model_def config/yolov3-custom.cfg --class_path data/classes.names --weights_path /mydrive/yolov3/wgts_50_74.weights  --checkpoint_model /mydrive/yolov3/checkpoints/yolov3_ckpt_49.pth --image_folder /mydrive/yolov3/test/samples"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Namespace(batch_size=1, checkpoint_model='/mydrive/yolov3/checkpoints/yolov3_ckpt_49.pth', class_path='data/custom/classes.names', conf_thres=0.4, image_folder='/mydrive/yolov3/test/samples', img_size=416, model_def='config/yolov3-custom.cfg', n_cpu=0, nms_thres=0.4, weights_path='/mydrive/yolov3/checkpoints/yolov3_ckpt_49.pth')\n","\n","Performing object detection:\n","\t+ Batch 0, Inference Time: 0:00:00.096581\n","\t+ Batch 1, Inference Time: 0:00:00.083676\n","\t+ Batch 2, Inference Time: 0:00:00.082740\n","\t+ Batch 3, Inference Time: 0:00:00.078909\n","\n","Saving images:\n","(0) Image: '/mydrive/yolov3/test/samples/SEQ_image_4.jpg'\n","(1) Image: '/mydrive/yolov3/test/samples/test_image_00004.jpg'\n","\t+ Label: Box, Conf: 0.99999\n","(2) Image: '/mydrive/yolov3/test/samples/test_image_00005.jpg'\n","\t+ Label: Box, Conf: 1.00000\n","(3) Image: '/mydrive/yolov3/test/samples/test_image_00006.jpg'\n","\t+ Label: Box, Conf: 0.99999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JM6dXCupgV1Y","executionInfo":{"status":"ok","timestamp":1616210109350,"user_tz":420,"elapsed":109587,"user":{"displayName":"Steve Mims","photoUrl":"","userId":"09331760011393309744"}},"outputId":"c4e21d79-232a-4c89-d91c-346fca411327"},"source":["#  This is junk\n","#\n","#%cd /mydrive/yolov3/\n","#!ls -al *.py\n","\n","#!python Add1000filename.py\n","\n","#!cp /mydrive/CS231A_project/Data/train_3D_yolov3_hot/train*.jpg /mydrive/CS231A_project/Data/train_3D_yolov3/images/.\n","#!cp /mydrive/CS231A_project/Data/train_3D_yolov3_hot/train*.txt /mydrive/CS231A_project/Data/train_3D_yolov3/labels/.\n","\n","#%cd /content/PyTorch-YOLOv3/data/custom/\n","#!cp /mydrive/CS231A_project/Data/train_3D_yolov3/custom_images.zip .\n","%cd /mydrive/CS231A_project/Data/train_3D_yolov3/\n","#%cd /mydrive/CS231A_project/Data/train_3D_yolov3/Data/custom/\n","#!pwd\n","#!zip -rq custom_images_hot.zip images\n","#!zip -rq custom_labels_hot.zip labels"],"execution_count":54,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/CS231A_project/Data/train_3D_yolov3\n","/content/gdrive/My Drive/CS231A_project/Data/train_3D_yolov3\n"],"name":"stdout"}]}]}